{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6681392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e985afa",
   "metadata": {},
   "source": [
    "# Exploratory data analysis and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d80bce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f165</th>\n",
       "      <th>f166</th>\n",
       "      <th>f167</th>\n",
       "      <th>f168</th>\n",
       "      <th>f169</th>\n",
       "      <th>f170</th>\n",
       "      <th>f171</th>\n",
       "      <th>f172</th>\n",
       "      <th>f173</th>\n",
       "      <th>f174</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-13.559</td>\n",
       "      <td>-21.407</td>\n",
       "      <td>-11.4040</td>\n",
       "      <td>-15.248</td>\n",
       "      <td>-11.923</td>\n",
       "      <td>-15.291</td>\n",
       "      <td>-2.1548</td>\n",
       "      <td>-7.8474</td>\n",
       "      <td>-10.0020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18519</td>\n",
       "      <td>0.72602</td>\n",
       "      <td>5.3333</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.29489</td>\n",
       "      <td>9.77780</td>\n",
       "      <td>2.44440</td>\n",
       "      <td>1.67700</td>\n",
       "      <td>0.20988</td>\n",
       "      <td>0.65422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-12.802</td>\n",
       "      <td>-20.335</td>\n",
       "      <td>-10.3990</td>\n",
       "      <td>-14.132</td>\n",
       "      <td>-11.096</td>\n",
       "      <td>-14.361</td>\n",
       "      <td>-2.4039</td>\n",
       "      <td>-7.5330</td>\n",
       "      <td>-9.9369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.33333</td>\n",
       "      <td>-0.48751</td>\n",
       "      <td>2.1111</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.83333</td>\n",
       "      <td>0.33333</td>\n",
       "      <td>0.33333</td>\n",
       "      <td>0.84869</td>\n",
       "      <td>0.50617</td>\n",
       "      <td>-0.18898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-12.431</td>\n",
       "      <td>-19.902</td>\n",
       "      <td>-10.0740</td>\n",
       "      <td>-13.598</td>\n",
       "      <td>-10.829</td>\n",
       "      <td>-14.048</td>\n",
       "      <td>-2.3566</td>\n",
       "      <td>-7.4717</td>\n",
       "      <td>-9.8283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25926</td>\n",
       "      <td>0.25298</td>\n",
       "      <td>2.2222</td>\n",
       "      <td>0.172840</td>\n",
       "      <td>0.68889</td>\n",
       "      <td>0.88889</td>\n",
       "      <td>0.66667</td>\n",
       "      <td>1.27300</td>\n",
       "      <td>0.30864</td>\n",
       "      <td>0.10483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-12.689</td>\n",
       "      <td>-19.529</td>\n",
       "      <td>-10.0280</td>\n",
       "      <td>-13.350</td>\n",
       "      <td>-11.056</td>\n",
       "      <td>-14.014</td>\n",
       "      <td>-2.6611</td>\n",
       "      <td>-6.8396</td>\n",
       "      <td>-9.5006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16049</td>\n",
       "      <td>0.43750</td>\n",
       "      <td>4.1111</td>\n",
       "      <td>0.320990</td>\n",
       "      <td>0.83333</td>\n",
       "      <td>0.33333</td>\n",
       "      <td>0.33333</td>\n",
       "      <td>1.14910</td>\n",
       "      <td>0.38272</td>\n",
       "      <td>0.41603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-12.686</td>\n",
       "      <td>-19.278</td>\n",
       "      <td>-9.8185</td>\n",
       "      <td>-13.108</td>\n",
       "      <td>-10.932</td>\n",
       "      <td>-13.939</td>\n",
       "      <td>-2.8675</td>\n",
       "      <td>-6.5919</td>\n",
       "      <td>-9.4594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18519</td>\n",
       "      <td>0.35000</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>0.444440</td>\n",
       "      <td>0.68889</td>\n",
       "      <td>0.88889</td>\n",
       "      <td>0.66667</td>\n",
       "      <td>1.58110</td>\n",
       "      <td>0.20988</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label      f1      f2       f3      f4      f5      f6      f7      f8  \\\n",
       "0      1 -13.559 -21.407 -11.4040 -15.248 -11.923 -15.291 -2.1548 -7.8474   \n",
       "1      1 -12.802 -20.335 -10.3990 -14.132 -11.096 -14.361 -2.4039 -7.5330   \n",
       "2      1 -12.431 -19.902 -10.0740 -13.598 -10.829 -14.048 -2.3566 -7.4717   \n",
       "3      1 -12.689 -19.529 -10.0280 -13.350 -11.056 -14.014 -2.6611 -6.8396   \n",
       "4      1 -12.686 -19.278  -9.8185 -13.108 -10.932 -13.939 -2.8675 -6.5919   \n",
       "\n",
       "        f9  ...     f165     f166    f167      f168     f169     f170  \\\n",
       "0 -10.0020  ...  0.18519  0.72602  5.3333  6.000000  0.29489  9.77780   \n",
       "1  -9.9369  ...  0.33333 -0.48751  2.1111  0.098765  0.83333  0.33333   \n",
       "2  -9.8283  ...  0.25926  0.25298  2.2222  0.172840  0.68889  0.88889   \n",
       "3  -9.5006  ...  0.16049  0.43750  4.1111  0.320990  0.83333  0.33333   \n",
       "4  -9.4594  ...  0.18519  0.35000  4.0000  0.444440  0.68889  0.88889   \n",
       "\n",
       "      f171     f172     f173     f174  \n",
       "0  2.44440  1.67700  0.20988  0.65422  \n",
       "1  0.33333  0.84869  0.50617 -0.18898  \n",
       "2  0.66667  1.27300  0.30864  0.10483  \n",
       "3  0.33333  1.14910  0.38272  0.41603  \n",
       "4  0.66667  1.58110  0.20988  0.50000  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('WinnipegDataset.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6597be7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    85074\n",
       "3    75673\n",
       "4    74067\n",
       "5    47117\n",
       "1    39162\n",
       "2     3598\n",
       "7     1143\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = df[0:50000]\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e46a60d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class share\n",
      "\n",
      "Class 1: 12.02 %\n",
      "Class 2: 1.10 %\n",
      "Class 3: 23.22 %\n",
      "Class 4: 22.73 %\n",
      "Class 5: 14.46 %\n",
      "Class 6: 26.11 %\n",
      "Class 7: 0.35 %\n"
     ]
    }
   ],
   "source": [
    "class_share = pd.Series(100 * df.label.value_counts(normalize=True)).sort_index()\n",
    "print('Class share\\n')\n",
    "for i in range(0,7):\n",
    "    print(f'Class {class_share.index[i]}: {class_share.iloc[i]:.2f} %')\n",
    "    \n",
    "#Below shows a somehow balanced distrbution, with exception in class 2 (Pea) and class 7 (Broadleaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ecb71dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Share (%)')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "sns.barplot(ax=ax, x = class_share.index, y = class_share, palette='Greens_d')\n",
    "plt.title('Cropland Class Share', fontsize=18)\n",
    "plt.xlabel('Cropland Class', fontsize=14)\n",
    "plt.ylabel('Share (%)', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdcfd41",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "112cc7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t8/4cz6934j38v_m257qfz846ym0000gn/T/ipykernel_19802/3470960586.py:5: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  upper_matrix = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(np.bool))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f2', 'f5', 'f6', 'f13', 'f15', 'f16', 'f17', 'f18', 'f30', 'f32', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f45', 'f46', 'f47', 'f49', 'f53', 'f54', 'f55', 'f62', 'f64', 'f65', 'f66', 'f67', 'f79', 'f81', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f92', 'f94', 'f95', 'f96', 'f98', 'f102', 'f108', 'f109', 'f111', 'f112', 'f113', 'f114', 'f116', 'f117', 'f120', 'f121', 'f127', 'f129', 'f133', 'f135', 'f146', 'f147', 'f148', 'f149', 'f152', 'f153', 'f154', 'f156', 'f157', 'f158', 'f159', 'f165', 'f171', 'f173']\n"
     ]
    }
   ],
   "source": [
    "highly_correlated_feature_pairs = []\n",
    "highly_correlated_features_to_drop = []\n",
    "\n",
    "correlation_matrix = df.corr().abs()\n",
    "upper_matrix = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(np.bool))\n",
    "for row in range(upper_matrix.shape[0]):\n",
    "    for column in range(upper_matrix.shape[1]):\n",
    "        if upper_matrix.iloc[row, column] > 0.95:\n",
    "            highly_correlated_feature_pairs.append([row, column, upper_matrix.iloc[row, column]])\n",
    "highly_correlated_features_to_drop = [column for column in upper_matrix.columns if any(upper_matrix[column] > 0.95)]\n",
    "print(highly_correlated_features_to_drop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b5e09d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Dropping highly correlated features\n",
    "df = df.drop(df[highly_correlated_features_to_drop], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7a00c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized number of features: 102\n"
     ]
    }
   ],
   "source": [
    "##the number of features was substantially reduced from 174 down to 102\n",
    "nr_features = df.shape[1] - 1\n",
    "print(f'Optimized number of features: {nr_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d00f1aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('label', axis = 1)\n",
    "y = df.label\n",
    "\n",
    "# Splitting Dataset into train and test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c39872",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bca704f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "#change to fit_resample\n",
    "#X_train, y_train = ros.fit_resample(Xtrain, y_train)\n",
    "def modeling(Model, Xtrain = X_train, Xtest = X_test):\n",
    "    model = Model\n",
    "    \n",
    "    #Xtrain = pca.fit_transform(Xtrain)\n",
    "    #Xtest = pca.transform(Xtest)\n",
    "    \n",
    "    # Fitting classifier to the Training set (all features)\n",
    "    model.fit(Xtrain, y_train)\n",
    "    \n",
    "    global y_pred\n",
    "    # Predicting the Test set results\n",
    "    y_pred = model.predict(Xtest)\n",
    "    \n",
    "    #Evaluating models\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='micro')\n",
    "    recall = recall_score(y_test, y_pred, average='micro')\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    \n",
    "    \n",
    "    # Printing evaluation metrics\n",
    "    print('Accuracy:', accuracy, ', Precision:', precision, ', Recall:', recall,' ,F1:', f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0445555b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7100986695720226 , Precision: 0.7100986695720226 , Recall: 0.7100986695720226  ,F1: 0.7100986695720226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patriciasiuhaliu/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "modeling(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a2fe913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9252535792655792 , Precision: 0.9252535792655792 , Recall: 0.9252535792655792  ,F1: 0.9252535792655792\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "modeling(GaussianNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a246baa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98798471619071 , Precision: 0.98798471619071 , Recall: 0.98798471619071  ,F1: 0.98798471619071\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "modeling(DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244bb887",
   "metadata": {},
   "source": [
    "### Unsupervised Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b33ef5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "# try different K value and find the best K for KMeans\n",
    "# Assumption: SSE is smaller, it is better\n",
    "\n",
    "Sum_of_squared_distances = []\n",
    "K = range(1,15)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km = km.fit(X)\n",
    "    Sum_of_squared_distances.append(km.inertia_)\n",
    "    \n",
    "# Plot K and SSE, observe which one is better\n",
    "# In the plot, the elbow on the arm is optimal k\n",
    "plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum_of_squared_distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caed08c",
   "metadata": {},
   "source": [
    "#### choosing 4 clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "218edf39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=4)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans=KMeans(n_clusters= 4)\n",
    "kmeans.fit(X)#training the unsupervised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f9303b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = df.drop('label', axis = 1) #dropping label\n",
    "km_pred = kmeans.predict(X2)\n",
    "X2['cluster'] = km_pred#adding a new column to X2 with the cluster index\n",
    "y2 = df.label\n",
    "\n",
    "#after adding the column we check if it is improving the accuracy of supervised learning or not\n",
    "# This way we evaliuate unsupervised, as there is not way to evalute unsupervised\n",
    "# Splitting Dataset into train and test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, y2, test_size=0.2)\n",
    "\n",
    "def modeling(Model, Xtrain = X_train, Xtest = X_test):\n",
    "    model = Model\n",
    "    \n",
    "    #Xtrain = pca.fit_transform(Xtrain)\n",
    "    #Xtest = pca.transform(Xtest)\n",
    "    \n",
    "    # Fitting classifier to the Training set (all features)\n",
    "    model.fit(Xtrain, y_train)\n",
    "    \n",
    "    global y_pred\n",
    "    # Predicting the Test set results\n",
    "    y_pred = model.predict(Xtest)\n",
    "    \n",
    "    #Evaluating models\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='micro')\n",
    "    recall = recall_score(y_test, y_pred, average='micro')\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    \n",
    "    \n",
    "    # Printing evaluation metrics\n",
    "    print('Accuracy:', accuracy, ', Precision:', precision, ', Recall:', recall,' ,F1:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61cff7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6942317430601378 , Precision: 0.6942317430601378 , Recall: 0.6942317430601378  ,F1: 0.6942317430601378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patriciasiuhaliu/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "modeling(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfbbea9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9266653367501957 , Precision: 0.9266653367501957 , Recall: 0.9266653367501957  ,F1: 0.9266653367501957\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "modeling(GaussianNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a15f51ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9873709085887029 , Precision: 0.9873709085887029 , Recall: 0.9873709085887029  ,F1: 0.9873709085887029\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "modeling(DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cefc96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After adding a cluster variable tothe features there is not much differnce in accuracy precision or recall\n",
    "# so we can say that unsupervised learning is not helpful in predicting the label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852e0016",
   "metadata": {},
   "source": [
    "### With PCA (95%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cd1bc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('label', axis = 1)\n",
    "y = df.label\n",
    "\n",
    "# Splitting Dataset into train and test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.95)# only those columns which explains 80% of the variance (of max accuracy) of the data\n",
    "#feature reduction pca helps to reduce computational load on system\n",
    "\n",
    "#change to fit_resample\n",
    "#X_train, y_train = ros.fit_resample(Xtrain, y_train)\n",
    "def modeling(Model, Xtrain = X_train, Xtest = X_test):\n",
    "    model = Model\n",
    "    \n",
    "    Xtrain = pca.fit_transform(Xtrain)# MAKES A matrix removing the not needed columns based on PCA\n",
    "    Xtest = pca.transform(Xtest)# MAKES A matrix removing the not needed columns based on PCA\n",
    "    \n",
    "    # Fitting classifier to the Training set (all features)\n",
    "    model.fit(Xtrain, y_train)\n",
    "    \n",
    "    global y_pred\n",
    "    # Predicting the Test set results\n",
    "    y_pred = model.predict(Xtest)\n",
    "    \n",
    "    #Evaluating models\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='micro')\n",
    "    recall = recall_score(y_test, y_pred, average='micro')\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    \n",
    "    \n",
    "    # Printing evaluation metrics\n",
    "    print('Accuracy:', accuracy, ', Precision:', precision, ', Recall:', recall,' ,F1:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff4e1fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6996946307180014 , Precision: 0.6996946307180014 , Recall: 0.6996946307180014  ,F1: 0.6996946307180014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patriciasiuhaliu/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "modeling(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe67c5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6431169150029923 , Precision: 0.6431169150029923 , Recall: 0.6431169150029923  ,F1: 0.6431169150029923\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "modeling(GaussianNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7d680af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6820783525403962 , Precision: 0.6820783525403962 , Recall: 0.6820783525403962  ,F1: 0.6820783525403962\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "modeling(DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e4d985",
   "metadata": {},
   "source": [
    "### With PCA ( 80% )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91af11d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('label', axis = 1)\n",
    "y = df.label\n",
    "\n",
    "# Splitting Dataset into train and test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.8)# only those columns which explains 80% of the variance (of max accuracy) of the data\n",
    "#feature reduction pca helps to reduce computational load on system\n",
    "\n",
    "#change to fit_resample\n",
    "#X_train, y_train = ros.fit_resample(Xtrain, y_train)\n",
    "def modeling(Model, Xtrain = X_train, Xtest = X_test):\n",
    "    model = Model\n",
    "    \n",
    "    Xtrain = pca.fit_transform(Xtrain)# MAKES A matrix removing the not needed columns based on PCA\n",
    "    Xtest = pca.transform(Xtest)# MAKES A matrix removing the not needed columns based on PCA\n",
    "    \n",
    "    # Fitting classifier to the Training set (all features)\n",
    "    model.fit(Xtrain, y_train)\n",
    "    \n",
    "    global y_pred\n",
    "    # Predicting the Test set results\n",
    "    y_pred = model.predict(Xtest)\n",
    "    \n",
    "    #Evaluating models\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='micro')\n",
    "    recall = recall_score(y_test, y_pred, average='micro')\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    \n",
    "    \n",
    "    # Printing evaluation metrics\n",
    "    print('Accuracy:', accuracy, ', Precision:', precision, ', Recall:', recall,' ,F1:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17737e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5185906977457916 , Precision: 0.5185906977457916 , Recall: 0.5185906977457916  ,F1: 0.5185906977457916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patriciasiuhaliu/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "modeling(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "823f7d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5344269338775761 , Precision: 0.5344269338775761 , Recall: 0.5344269338775761  ,F1: 0.5344269338775761\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "modeling(GaussianNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "faa349d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.42291343778292695 , Precision: 0.42291343778292695 , Recall: 0.42291343778292695  ,F1: 0.4229134377829269\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "modeling(DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a9c187",
   "metadata": {},
   "source": [
    "### With PCA (30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b898e826",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('label', axis = 1)\n",
    "y = df.label\n",
    "\n",
    "# Splitting Dataset into train and test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.3)\n",
    "\n",
    "#change to fit_resample\n",
    "#X_train, y_train = ros.fit_resample(Xtrain, y_train)\n",
    "def modeling(Model, Xtrain = X_train, Xtest = X_test):\n",
    "    model = Model\n",
    "    \n",
    "    Xtrain = pca.fit_transform(Xtrain)\n",
    "    Xtest = pca.transform(Xtest)\n",
    "    \n",
    "    # Fitting classifier to the Training set (all features)\n",
    "    model.fit(Xtrain, y_train)\n",
    "    \n",
    "    global y_pred\n",
    "    # Predicting the Test set results\n",
    "    y_pred = model.predict(Xtest)\n",
    "    \n",
    "    #Evaluating models\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='micro')\n",
    "    recall = recall_score(y_test, y_pred, average='micro')\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    \n",
    "    \n",
    "    # Printing evaluation metrics\n",
    "    print('Accuracy:', accuracy, ', Precision:', precision, ', Recall:', recall,' ,F1:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52fc47f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5249282612365154 , Precision: 0.5249282612365154 , Recall: 0.5249282612365154  ,F1: 0.5249282612365154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patriciasiuhaliu/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "modeling(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1f4cca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5326622370218055 , Precision: 0.5326622370218055 , Recall: 0.5326622370218055  ,F1: 0.5326622370218055\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "modeling(GaussianNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e9cc728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.42384949437598785 , Precision: 0.42384949437598785 , Recall: 0.42384949437598785  ,F1: 0.42384949437598785\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "modeling(DecisionTreeClassifier())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
